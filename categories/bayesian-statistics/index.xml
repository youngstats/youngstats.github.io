<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>bayesian-statistics on YoungStatS</title>
    <link>https://youngstats.github.io/categories/bayesian-statistics/</link>
    <description>Recent content in bayesian-statistics on YoungStatS</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 14 Feb 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://youngstats.github.io/categories/bayesian-statistics/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Selection of Priors in Bayesian Structural Equation Modeling</title>
      <link>https://youngstats.github.io/post/2022/02/14/selection-of-priors-in-bayesian-structural-equation-modeling/</link>
      <pubDate>Mon, 14 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://youngstats.github.io/post/2022/02/14/selection-of-priors-in-bayesian-structural-equation-modeling/</guid>
      <description>Selection of Priors in Bayesian Structural Equation Modelling
Structural equation modeling (SEM) is an important framework within the social sciences that encompasses a wide variety of statistical models. Traditionally, estimation of SEMs has relied on maximum likelihood. Unfortunately, there also exist a variety of situations in which maximum likelihood performs subpar. This led researchers to turn to alternative estimation methods, in particular, Bayesian estimation of SEMs or BSEM. However, it is currently unclear how to specify the prior distribution in order to attain the advantages of Bayesian approaches.</description>
    </item>
    
    <item>
      <title>Recent Advances in Approximate Bayesian Inference</title>
      <link>https://youngstats.github.io/post/2022/02/08/recent-advances-in-approximate-bayesian-inference/</link>
      <pubDate>Tue, 08 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://youngstats.github.io/post/2022/02/08/recent-advances-in-approximate-bayesian-inference/</guid>
      <description>Recent Advances in Approximate Bayesian Inference
In approximate Bayesian computation, likelihood function is intractable and needs to be itself estimated using forward simulations of the statistical model (Beaumont et al., 2002; Marin et al., 2012; Sisson et al., 2019; Martin et al., 2020). Recent years have seen numerous advances in approximate inference methods, which have enabled Bayesian inference in increasingly challenging scenarios involving complex probabilistic models and large datasets.</description>
    </item>
    
    <item>
      <title>Measuring dependence in the Wasserstein distance for Bayesian nonparametric models</title>
      <link>https://youngstats.github.io/post/2022/01/17/measuring-dependence-in-the-wasserstein-distance-for-bayesian-nonparametric-models/</link>
      <pubDate>Mon, 17 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://youngstats.github.io/post/2022/01/17/measuring-dependence-in-the-wasserstein-distance-for-bayesian-nonparametric-models/</guid>
      <description>OverviewBayesian nonparametric (BNP) models are a prominent tool for performing flexible inference with a natural quantification of uncertainty. Traditionallly, flexible inference within a homogeneous sample is performed with exchangeable models of the type \(X_1,\dots, X_n|\tilde \mu \sim T(\tilde \mu)\), where \(\tilde \mu\) is a random measure and \(T\) is a suitable transformation. Notable examples for \(T\) include normalization for random probabilities (Regazzini et al., 2003), kernel mixtures for densities (Lo, 1984) and for hazards (Dykstra and Laud, 1981; James, 2005), exponential transformations for survival functions (Doksum, 1974) and cumulative transformations for cumulative hazards (Hjort, 1990).</description>
    </item>
    
    <item>
      <title>Universal estimation with Maximum Mean Discrepancy (MMD)</title>
      <link>https://youngstats.github.io/post/2022/01/13/universal-estimation-with-maximum-mean-discrepancy-mmd/</link>
      <pubDate>Thu, 13 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://youngstats.github.io/post/2022/01/13/universal-estimation-with-maximum-mean-discrepancy-mmd/</guid>
      <description>This is an updated version of a blog post on RIKEN AIP Approximate Bayesian Inference team webpage: https://team-approx-bayes.github.io/blog/mmd/
INTRODUCTIONA very old and yet very exciting problem in statistics is the definition of a universal estimator \(\hat{\theta}\). An estimation procedure that would work all the time. Close your eyes, push the button, it works, for any model, in any context.
Formally speaking, we want that for some metric \(d\) on probability distributions, for any statistical model \((P_\theta,\theta\in\Theta)\), given \(X_1,\dots,X_n\) drawn i.</description>
    </item>
    
    <item>
      <title>Optimal disclosure risk assessment</title>
      <link>https://youngstats.github.io/post/2021/09/30/optimal-disclosure-risk-assessment/</link>
      <pubDate>Thu, 30 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://youngstats.github.io/post/2021/09/30/optimal-disclosure-risk-assessment/</guid>
      <description>Disclosure risk for microdataProtection against disclosure is a legal and ethical obligation foragencies releasing microdata files for public use. Consider a microdatasample \({X}_n=(X_{1},\ldots,X_{n})\) of size \(n\) from a finitepopulation of size \(\bar{n}=n+\lambda n\), with \(\lambda&amp;gt;0\), such thateach sample record \(X_i\) contains two disjoint types of information:identifying categorical information and sensitive information.Identifying information consists of a set of categorical variables whichmight be matchable to known units of the population.</description>
    </item>
    
    <item>
      <title>Optional stopping with Bayes factors: possibilities and limitations</title>
      <link>https://youngstats.github.io/post/2021/06/10/optional-stopping-with-bayes-factors-possibilities-and-limitations/</link>
      <pubDate>Thu, 10 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://youngstats.github.io/post/2021/06/10/optional-stopping-with-bayes-factors-possibilities-and-limitations/</guid>
      <description>In recent years, a surprising number of scientific results have failedto hold up to continued scrutiny. Part of this ‘replicability crisis’may be caused by practices that ignore the assumptions of traditional(frequentist) statistical methods (John, Loewenstein, and Prelec 2012). One ofthese assumptions is that the experimental protocol should be completelydetermined upfront. In practice, researchers often adjust the protocoldue to unforeseen circumstances or collect data until a point has beenproven.</description>
    </item>
    
    <item>
      <title>Developments in Bayesian Nonparametrics (updated with slides)</title>
      <link>https://youngstats.github.io/post/2021/04/06/bnp-webinar/</link>
      <pubDate>Tue, 06 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://youngstats.github.io/post/2021/04/06/bnp-webinar/</guid>
      <description>The second &amp;ldquo;One World webinar&amp;rdquo; organized by YoungStatS will take place on April 21st. The focus of this webinar will be on illustrating modern advances in Bayesian Nonparametrics data analysis, discussing challenging theoretical problems and stimulating case-studies within this active area of research.
When &amp;amp; Where:
 Wednesday, April 21st, 16:30 CEST Online, via Zoom. The registration form is available here. Further details and the Zoom link will be sent to the registered addresses only.</description>
    </item>
    
    <item>
      <title>A Scalable Empirical Bayes Approach to Variable Selection in Generalized Linear Models</title>
      <link>https://youngstats.github.io/post/2021/03/13/a-scalable-empirical-bayes-approach-to-variable-selection-in-generalized-linear-models/</link>
      <pubDate>Sat, 13 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://youngstats.github.io/post/2021/03/13/a-scalable-empirical-bayes-approach-to-variable-selection-in-generalized-linear-models/</guid>
      <description>In the toolbox of most scientists over the past century, there have been few methods as powerful and as versatile as linear regression. The introduction of the generalized linear model (GLM) framework in the 1970’s extended the inferential and predictive capabilities to binary or count data. While the effect of this ‘Swiss Army knife’ of scientific research cannot be overstated, rapid (and amazing) technological advances in other areas have pushed it beyond its theoretical capacity.</description>
    </item>
    
    <item>
      <title>Machine learning for causal inference that works</title>
      <link>https://youngstats.github.io/post/2021/01/26/machine-learning-for-causal-inference-that-works/</link>
      <pubDate>Tue, 26 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://youngstats.github.io/post/2021/01/26/machine-learning-for-causal-inference-that-works/</guid>
      <description>I’ve kindly been invited to share a few words about a recent paper my colleagues and I published in Bayesian Analysis: “Bayesian Regression Tree Models for Causal Inference: Regularization, Confounding, and Heterogeneous Effects”. In that paper, we motivate and describe a method that we call Bayesian causal forests (BCF), which is now implemented in an R package called bcf.
The goal of this post is to work through a simple toy example to illustrate the strengths of BCF.</description>
    </item>
    
  </channel>
</rss>
