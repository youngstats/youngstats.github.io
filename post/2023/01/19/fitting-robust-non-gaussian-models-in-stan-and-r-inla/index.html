<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <title>Fitting robust non-Gaussian models in Stan and R-INLA | YoungStatS</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    <link href="//cdn.bootcss.com/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">

  </head>

  <body class="page">
    <nav class="header">
      <div class="banner">
<a href="/" class="text">
<div class="yourfancytitle"> YoungStatS </div> 
</a>
</div>

      <div class="head-meta">
      
        <span><a href="/">&larr; Back to Home</a></span>
       <span>The blog of Young Statisticians Europe (YSE)</span>
        
        
        
          
        
        
        
        
      
      </div>
    </nav>
    
    <footer>
<script src="//yihui.org/js/math-code.js"></script>
<script async
src="cdnjs.cloudflare.com/ajax/libs/mathjax/3.1.0?config=TeX-MML-AM_CHTML">
</script>
<div class="footer">
  <ul class="menu">
    
    <li><a href="/"><span data-hover="Home">Home</span></a></li>
    
    <li><a href="/categories/webinars"><span data-hover="Webinars">Webinars</span></a></li>
    
    <li><a href="/about/"><span data-hover="About">About</span></a></li>
    
    <li><a href="/categories/"><span data-hover="Categories">Categories</span></a></li>
    
  </ul>
  
</div>
</footer>

<div class="container">
<article>
<div class="article-meta">

  <div class="categories">
  
    <a href="/categories/bayesian-statistics">bayesian-statistics</a>
  
     &hercon; <a href="/categories/bayesian-computation">bayesian-computation</a>
  
     &hercon; <a href="/categories/robust-statistics">robust-statistics</a>
  
  </div>

  <h1><span class="title">Fitting robust non-Gaussian models in Stan and R-INLA</span></h1>

  
  <h3 class="author">Rafael Cabral,  David Bolin and Haavard Rue
</h3>
  

  
  

</div>



<main>



<div id="overview" class="section level2">
<h2>Overview</h2>
<p>Traditionally the excitation noise of spatial and temporal models is Gaussian. Take, for instance, an AR1 (autoregressive of order 1) process, where the increments <span class="math inline">\(x_{i+1}-\rho x_i, \ \ |\rho|&lt;1\)</span> are assumed to follow a Gaussian distribution. However, it is easy to find datasets that contain inherently non-Gaussian features, such as sudden jumps or spikes, that adversely affect the inferences and predictions made from Gaussian models. In this post, we introduce a specific class of non-Gaussian models, their advantages over Gaussian models, and their Bayesian implementation in Stan and R-INLA, two well-established platforms for statistical modeling.</p>
</div>
<div id="why-go-beyond-gaussian-models" class="section level2">
<h2>Why go beyond Gaussian models?</h2>
<p>Often, these Gaussian and non-Gaussian models are used as latent components in hierarchical models leading to latent Gaussian models (LGMs) and latent non-Gaussian models (LnGMs), respectively. We highlight next the benefits of using a (latent) non-Gaussian model:</p>
<ol style="list-style-type: decimal">
<li><strong>More accurate predictions</strong>. <span class="citation">Asar et al. (<a href="#ref-asar2020linear" role="doc-biblioref">2020</a>)</span> considered measurements related to the kidney function of several patients recorded over time. The LGM did not adapt well to sudden drops in measurements, as shown in the following figure, which was problematic since these drops are an example of “acute kidney injury”, which should prompt an immediate medical intervention. The red curve shows a prediction based on an LnGM, which clearly is more accurate.</li>
</ol>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><img src="/post/2023-01-19-fitting-robust-non-gaussian-models-in-stan-and-r-inla_files/Cabral_Image1_time_series.png" /></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><b> Observations of a quantity related to a patient’s kidney function and predictions using an LGM (green) and an LnGM (red). </b></td>
</tr>
</tbody>
</table>
<ol start="2" style="list-style-type: decimal">
<li><p><strong>Robustness</strong>. Non-Gaussian models provide a means for both accommodating possible outliers in the data and reduce their impact on the inferences (<span class="citation">West (<a href="#ref-west1984outlier" role="doc-biblioref">1984</a>)</span>)</p></li>
<li><p><strong>Model checking</strong>. We often elicit a Gaussian model for simplicity and convenience in a somewhat casual fashion. However, we can fit a non-Gaussian model, and if the relevant inferences do not change significantly, this can confirm the reasonableness of the Gaussian assumption.</p></li>
</ol>
</div>
<div id="what-type-of-non-gaussian-models-are-you-considering" class="section level2">
<h2>What type of non-Gaussian models are you considering?</h2>
<p>If <span class="math inline">\(\mathbf{x}^G\)</span> follows a multivariate Gaussian with mean <span class="math inline">\(\mathbf{0}\)</span> and precision matrix <span class="math inline">\(\mathbf{Q}= \mathbf{\mathbf{D}}^T\mathbf{D}\)</span>, it can be expressed through</p>
<p><span class="math display">\[
\mathbf{D}\mathbf{x}^G\overset{d}{=} \sigma\mathbf{Z},
\]</span>
where <span class="math inline">\(\mathbf{Z}\)</span> is a vector of i.i.d. standard Gaussian variables. The non-Gaussian extension for <span class="math inline">\(\mathbf{x}^G\)</span> consists in replacing the driving noise distribution:
<span class="math display">\[
\mathbf{D}\mathbf{x}\overset{d}{=} \sigma \mathbf{\Lambda}(\eta,\zeta),
\]</span>
where <span class="math inline">\(\boldsymbol{\Lambda}\)</span> is a vector of independent and standardized normal-inverse Gaussian (NIG) random variables that depend on the parameter <span class="math inline">\(\eta\)</span> and <span class="math inline">\(\zeta\)</span>, which controls the leptokurtosis and skewness of the driving noise. <span class="citation">Cabral, Bolin, and Rue (<a href="#ref-cabral2022controlling" role="doc-biblioref">2022a</a>)</span> presented these models as flexible extensions of Gaussian models because they contain the Gaussian model as a special case (when <span class="math inline">\(\eta=0\)</span>), and deviations from the Gaussian model are quantified by the parameters <span class="math inline">\(\eta\)</span> and <span class="math inline">\(\zeta\)</span>. These models admit a useful variance-mean mixture representation. Considering the mixing variables <span class="math inline">\(\mathbf{V}= [V_1, \dotsc, V_n]^T\)</span> we have:</p>
<p><span class="math display">\[\begin{equation}   \label{eq:model}
\tag{1}
\mathbf{x}|\mathbf{V} \sim \text{N}\left(\frac{\sigma}{\sqrt{1+\zeta^2\eta}} \zeta \mathbf{D}^{-1}(\mathbf{V}-\mathbf{1}),\frac{\sigma^2}{1+\zeta^2\eta} \mathbf{D}^{-1}\text{diag}(\mathbf{V})\mathbf{D}^{-T} \right), \ \ \  V_{i}|\eta \overset{ind.}{\sim} \mathrm{IG}(1,\eta^{-1} h_i^2),
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\mathrm{IG}\)</span> stands for the inverse-Gaussian distribution. We condition the Gaussian latent field <span class="math inline">\(\mathbf{x}\)</span> on a vector of mixing variables <span class="math inline">\(\mathbf{V}\)</span>, which enter the covariance matrix, adding more flexibility to the model. We note that the previous parameterization preserves the mean and covariance structure of <span class="math inline">\(\mathbf{x}\)</span> while allowing for non-zero skewness and excess kurtosis on the marginal distributions.</p>
<p>This non-Gaussian extension can be used in: random walk (RW) and autoregressive processes for time series; simultaneous and conditional autoregressive processes for graphical models and areal data; Matérn processes, which can be used in a variety of applications, such as in geostatistics and spatial point processes. The corresponding dependency matrices <span class="math inline">\(\mathbf{D}\)</span> that specify each model can be found in <span class="citation">Cabral, Bolin, and Rue (<a href="#ref-cabral2022fitting" role="doc-biblioref">2022b</a>)</span>.</p>
</div>
<div id="what-sample-paths-do-these-models-produce" class="section level2">
<h2>What sample paths do these models produce?</h2>
<p>The first row of the following figure shows Gaussian (left) and NIG (right) white noise processes. The rows below show several processes built from these driving noises, including RW1, RW2, Ornstein–Uhlenbeck (OU), and Matérn (<span class="math inline">\(\alpha=2\)</span>) processes. Whenever the NIG noise takes an extreme value (for instance, near location 0.8), the CRW1 and OU processes will exhibit a distinct jump, and the RW2 and Matérn processes will exhibit a kink (discontinuity in the first derivative).</p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><img src="/post/2023-01-19-fitting-robust-non-gaussian-models-in-stan-and-r-inla_files/Cabral_Image2_simulation.png" /></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><b> Noise and sample paths of several models for <span class="math inline">\(\eta=10^{-6}\)</span> (left) and <span class="math inline">\(\eta=1\)</span> (right), for <span class="math inline">\(\sigma=1\)</span> and <span class="math inline">\(\zeta=0\)</span>. </b></td>
</tr>
</tbody>
</table>
</div>
<div id="stan-implementation" class="section level2">
<h2>Stan implementation</h2>
<p>The Gaussian model (<span class="math inline">\(\mathbf{D}\mathbf{x}^G = \mathbf{Z}\)</span>) can be declared in Stan as:</p>
<pre><code>x ~ multi_normal_prec(rep_vector(0,N), D&#39;*D)</code></pre>
<p>The non-Gaussian model (<span class="math inline">\(\mathbf{D}\mathbf{x} = \mathbf{\Lambda}\)</span>) declaration is:</p>
<pre><code>x ~ nig_model(D, eta, zeta, h, 1)</code></pre>
<p>The argument <code>h</code> should be a vector of ones for discrete-space models. For models defined in continuous space, for instance, a continuous random walk of order 1, <code>h</code> contains the distance between locations. The last argument is an integer with value 1 if the log-determinant of <span class="math inline">\(\mathbf{D}\)</span> should be computed (if <span class="math inline">\(\mathbf{D}\)</span> depends on parameters), or 0 otherwise. The <code>nig_model</code> and other Stan functions can be found in <a href="https://github.com/rafaelcabral96/nigstan">github.com/rafaelcabral96/nigstan</a>, along with a more comprehensive theoretical background and several code examples for time series, geostatistical and areal data application. The function <code>nig_model</code> uses a collapsed representation of (1) and leverages within-chain parallelization to improve speed and scalability.</p>
</div>
<div id="fitting-a-non-gaussian-model-in-stan-columbus-dataset" class="section level2">
<h2>Fitting a non-Gaussian model in Stan (Columbus dataset)</h2>
<p>The Columbus dataset consists of crime rates in thousands (<span class="math inline">\(y_i\)</span>) in 49 counties of Columbus, Ohio, and can be found in the <code>spdep</code> R package. The next Leaflet widget shows the crime rates.</p>
<div class="line-block"><img src="/post/2023-01-19-fitting-robust-non-gaussian-models-in-stan-and-r-inla_files/Cabral_Image_3_Columbus.png" />|</div>
<p>We consider the following model:</p>
<p><span class="math display">\[
y_i= \beta_0 + \beta_1 \text{HV}_i + \beta_2 \text{HI}_i +  \sigma\mathbf{x}_i,
\]</span>
where <span class="math inline">\(\text{HV}_i\)</span> and <span class="math inline">\(\text{HI}_i\)</span> are the average household value and household income for county <span class="math inline">\(i\)</span>, and <span class="math inline">\(\mathbf{x}\)</span> is a simultaneous autoregressive (SAR) model to account for spatially structured random effects. We consider a Gaussian SAR model built from the following relationship:</p>
<p><span class="math display">\[
\mathbf{x} = \mathbf{B}\mathbf{x} + \sigma\mathbf{Z},
\]</span>
where each element of the random vector <span class="math inline">\(\mathbf{x}\)</span> corresponds to a county and <span class="math inline">\(\mathbf{Z}\)</span> is a vector of i.i.d. standard Gaussian noise. The matrix <span class="math inline">\(\mathbf{B}\)</span> causes simultaneous autoregressions of each county on its neighbors, where two counties are considered to be neighbors if they share a common border. The diagonal elements of <span class="math inline">\(\mathbf{B}\)</span> are 0 so each node does not depend on itself. For simplicity, we assume <span class="math inline">\(\mathbf{B}=\rho\mathbf{W}\)</span>, where <span class="math inline">\(\mathbf{W}\)</span> is a row standardized adjacency matrix and <span class="math inline">\(-1&lt;\rho&lt;1\)</span> so that the resulting precision matrix is valid. We end up with the system <span class="math inline">\(\mathbf{D}_{SAR}\mathbf{x} = \sigma\mathbf{Z}\)</span>, where <span class="math inline">\(\mathbf{D}_{SAR}=\mathbf{I}-\rho\mathbf{W}\)</span>. The equivalent model driven by NIG noise is then <span class="math inline">\(\mathbf{D}_{SAR}\mathbf{x} = \sigma\mathbf{\Lambda}\)</span>, where <span class="math inline">\(\mathbf{\Lambda}\)</span> is i.i.d. standardized NIG noise with parameters <span class="math inline">\(\eta\)</span> and <span class="math inline">\(\zeta\)</span>.</p>
<p>The code for the Stan implementation can be found in this <a href="https://github.com/stan-dev/connect22-space-time/tree/main/resources/Speaker%203%20-%20Rafael%20Cabral">link</a>. Let <span class="math inline">\(\mathbf{B}\)</span> and <span class="math inline">\(\mathbf{\beta}=[\beta_0,\beta_1,\beta_2]^T\)</span> stand for the design matrix and the regression coefficients, respectively. Then, the Stan declaration for the Gaussian and non-Gaussian models is as follows:</p>
<pre><code>transformed parameters{
  vector[N] X = (y - B*beta)/sigma;                       // Spatial effects
}

model{

  matrix[N,N] D = add_diag(-rho*W, 1);                    // D = I - rho W;

  //Gaussian model
  //X ~ multi_normal_prec(rep_vector(0,N), D&#39;*D);   
  
  //NIG model
  X ~ nig_model(D, etas, zetas, h, 1);</code></pre>
<p>The posterior mean and standard deviation of the spatial effects can be found on the Leaflet widget. The widget also shows the posterior mean of the mixing variables <span class="math inline">\(\mathbf{V}\)</span>, and from it, we can identify two outlier counties. The posterior distributions of <span class="math inline">\(\eta\)</span> and <span class="math inline">\(\zeta\)</span> suggest heavy-tailedness, although no asymmetry, as shown in the following table.</p>
<table>
<thead>
<tr class="header">
<th align="left">variable</th>
<th align="right">mean</th>
<th align="right">median</th>
<th align="right">sd</th>
<th align="right">mad</th>
<th align="right">q5</th>
<th align="right">q95</th>
<th align="right">rhat</th>
<th align="right">ess_bulk</th>
<th align="right">ess_tail</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">sigma</td>
<td align="right">27.41</td>
<td align="right">27.32</td>
<td align="right">3.34</td>
<td align="right">3.34</td>
<td align="right">22.10</td>
<td align="right">33.10</td>
<td align="right">1</td>
<td align="right">4578.12</td>
<td align="right">5636.57</td>
</tr>
<tr class="even">
<td align="left">rho</td>
<td align="right">0.51</td>
<td align="right">0.52</td>
<td align="right">0.19</td>
<td align="right">0.20</td>
<td align="right">0.15</td>
<td align="right">0.80</td>
<td align="right">1</td>
<td align="right">3505.46</td>
<td align="right">3361.02</td>
</tr>
<tr class="odd">
<td align="left">eta</td>
<td align="right">6.51</td>
<td align="right">6.26</td>
<td align="right">2.45</td>
<td align="right">2.38</td>
<td align="right">2.95</td>
<td align="right">10.94</td>
<td align="right">1</td>
<td align="right">5081.12</td>
<td align="right">5061.76</td>
</tr>
<tr class="even">
<td align="left">zeta</td>
<td align="right">-0.11</td>
<td align="right">-0.01</td>
<td align="right">0.76</td>
<td align="right">0.23</td>
<td align="right">-1.53</td>
<td align="right">1.27</td>
<td align="right">1</td>
<td align="right">1895.06</td>
<td align="right">2635.10</td>
</tr>
<tr class="odd">
<td align="left">beta[0]</td>
<td align="right">59.30</td>
<td align="right">60.42</td>
<td align="right">16.32</td>
<td align="right">12.13</td>
<td align="right">33.02</td>
<td align="right">81.45</td>
<td align="right">1</td>
<td align="right">2091.19</td>
<td align="right">2467.55</td>
</tr>
<tr class="even">
<td align="left">beta[1]</td>
<td align="right">-0.15</td>
<td align="right">-0.14</td>
<td align="right">0.14</td>
<td align="right">0.13</td>
<td align="right">-0.39</td>
<td align="right">0.07</td>
<td align="right">1</td>
<td align="right">3542.21</td>
<td align="right">3231.01</td>
</tr>
<tr class="odd">
<td align="left">beta[2]</td>
<td align="right">-1.45</td>
<td align="right">-1.45</td>
<td align="right">0.57</td>
<td align="right">0.57</td>
<td align="right">-2.38</td>
<td align="right">-0.50</td>
<td align="right">1</td>
<td align="right">2892.18</td>
<td align="right">4458.28</td>
</tr>
</tbody>
</table>
</div>
<div id="r-inla-implementation" class="section level2">
<h2>R-INLA implementation</h2>
<p>To account for measurement error, we can consider the following hierarchical model:</p>
<p><span class="math display">\[\begin{equation*}
y_i|\mu_i \sim N(\mu_i, \sigma_\epsilon^2), \\
\mu_i = \beta_0 + \beta_1 \text{HV}_i + \beta_2 \text{HI}_i +  \sigma\mathbf{x}_i,
\end{equation*}\]</span>
where <span class="math inline">\(\sigma_\epsilon^2\)</span> is the measurement error variance, and now the non-Gaussian SAR model <span class="math inline">\(\mathbf{x}\)</span> is a latent component. When fitting latent models, such as the previous one, the posterior distribution often induces a geometry that frustrates sampling algorithms, such as Stan’s Hamiltonian Monte Carlo (<span class="citation">Margossian et al. (<a href="#ref-margossian2020approximate" role="doc-biblioref">2020</a>)</span>).</p>
<p>Recent work on fitting latent non-Gaussian models (LnGMs) using variational Bayes and Laplace approximations permits fast and scalable estimation of these models. The approximation uses R-INLA (<span class="citation">Rue, Martino, and Chopin (<a href="#ref-rue2009approximate" role="doc-biblioref">2009</a>)</span>), and the methods are implemented in the <em>ngvb</em> package (<span class="citation">Cabral, Bolin, and Rue (<a href="#ref-cabral2022fitting" role="doc-biblioref">2022b</a>)</span>). The previous latent SAR model is implemented in the <em>ngvb</em> package <a href="https://rafaelcabral96.github.io/ngvb/articles/ngvb.html">vignette</a>. There was significant evidence for non-Gaussianity since the Bayes factor between the fitted LGM and LnGM was around 80.000.</p>
</div>
<div id="about-the-authors" class="section level2">
<h2>About the Authors</h2>
<p><strong>Rafael Cabral</strong> (corresponding author) PhD student in Statistics at KAUST. Academic <a href="https://rafaelcabral96.github.io/">Website</a>.</p>
<p><strong>David Bolin</strong> Associate Professor of Statistics at KAUST. Principal investigator of the <a href="https://cemse.kaust.edu.sa/stochproc">Stochastic Processes and Applied Statistics group</a>.</p>
<p><strong>Haavard Rue</strong> Professor of Statistics at KAUST. Principal investigator of the <a href="https://cemse.kaust.edu.sa/bayescomp">Bayesian Computational Statistics &amp; Modeling group</a>.</p>
</div>
<div id="bibliography" class="section level2 unnumbered">
<h2>Bibliography</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-asar2020linear" class="csl-entry">
Asar, Özgür, David Bolin, Peter J Diggle, and Jonas Wallin. 2020. <span>“Linear Mixed Effects Models for Non-Gaussian Continuous Repeated Measurement Data.”</span> <em>Journal of the Royal Statistical Society: Series C (Applied Statistics)</em> 69 (5): 1015–65.
</div>
<div id="ref-cabral2022controlling" class="csl-entry">
Cabral, Rafael, David Bolin, and Håvard Rue. 2022a. <span>“Controlling the Flexibility of Non-Gaussian Processes Through Shrinkage Priors.”</span> <em>arXiv Preprint arXiv:2203.05510</em>.
</div>
<div id="ref-cabral2022fitting" class="csl-entry">
———. 2022b. <span>“Fitting Latent Non-Gaussian Models Using Variational Bayes and Laplace Approximations.”</span> <em>arXiv Preprint arXiv:2211.11050</em>.
</div>
<div id="ref-margossian2020approximate" class="csl-entry">
Margossian, Charles C, Aki Vehtari, Daniel Simpson, and Raj Agrawal. 2020. <span>“Approximate Bayesian Inference for Latent Gaussian Models in Stan.”</span> <em>Stan Con 2020</em>.
</div>
<div id="ref-rue2009approximate" class="csl-entry">
Rue, Håvard, Sara Martino, and Nicolas Chopin. 2009. <span>“Approximate Bayesian Inference for Latent Gaussian Models by Using Integrated Nested Laplace Approximations.”</span> <em>Journal of the Royal Statistical Society: Series b (Statistical Methodology)</em> 71 (2): 319–92.
</div>
<div id="ref-west1984outlier" class="csl-entry">
West, Mike. 1984. <span>“Outlier Models and Prior Distributions in Bayesian Linear Regression.”</span> <em>Journal of the Royal Statistical Society: Series B (Methodological)</em> 46 (3): 431–39.
</div>
</div>
</div>

</main>


















</article>
</div>

<script async src="//yihui.name/js/center-img.js"></script>
 


<script src="//yihui.name/js/math-code.js"></script>
<script async src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>



<script src="//cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.12.0/languages/r.min.js"></script>
<script>
hljs.configure({languages: []});
hljs.initHighlightingOnLoad();
</script>




</body>
</html>

