<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on YoungStatS</title>
    <link>https://youngstats.github.io/post/</link>
    <description>Recent content in Posts on YoungStatS</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 06 Jan 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://youngstats.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Reconciling the Gaussian and Whittle Likelihood with an application to estimation in the frequency domain</title>
      <link>https://youngstats.github.io/post/2022/01/06/reconciling-the-gaussian-and-whittle-likelihood/</link>
      <pubDate>Thu, 06 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://youngstats.github.io/post/2022/01/06/reconciling-the-gaussian-and-whittle-likelihood/</guid>
      <description>OverviewSuppose \(\{X_t: t\in \mathbb{Z}\}\) is a second order stationary time series where \(c(r) = \text{cov}(X_{t+r},X_t)\) and \(f(\omega) = \sum_{r\in\mathbb{Z}}c(r)e^{ir\omega}\) are the corresponding autocovariance and spectral density function, respectively. For notational convenience, we assume the time series is centered, that is \(\textrm{E}(X_t)=0\).Our aim is to fit a parametric second-order stationary model (specified by \(\{c_{f_\theta}(r)\}\) or \(f_\theta(\omega)\)) to the observed time series \(\underline{X}_n = (X_1, ..., X_n)^\top\).There are two classical estimation methods based on the quasi-likelihood criteria.</description>
    </item>
    
    <item>
      <title>Inclusion Process and Sticky Brownian Motions</title>
      <link>https://youngstats.github.io/post/2021/12/24/inclusion-process-and-sticky-brownian-motions/</link>
      <pubDate>Fri, 24 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://youngstats.github.io/post/2021/12/24/inclusion-process-and-sticky-brownian-motions/</guid>
      <description>Inclusion Process and Sticky Brownian Motions
The ninth “One World webinar” organized by YoungStatS will take place onFebruary 9th, 2022. Inclusion process (IP) is a stochastic lattice gaswhere particles perform random walks subjected to mutual attraction. Forthe inclusion process in the condensation regime one can extract thatthe scaling limit of two particles is a pair of sticky Brownian motionswhich lead to interesting recent research.</description>
    </item>
    
    <item>
      <title>Heterogeneous Treatment Effects with Instrumental Variables: A Causal Machine Learning Approach</title>
      <link>https://youngstats.github.io/post/2021/12/06/heterogeneous-treatment-effects-with-instrumental-variables-a-causal-machine-learning-approach/</link>
      <pubDate>Mon, 06 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://youngstats.github.io/post/2021/12/06/heterogeneous-treatment-effects-with-instrumental-variables-a-causal-machine-learning-approach/</guid>
      <description>Problem SettingIn our forthcoming paper on Annals of Applied Statistics, we propose a new method – which we call Bayesian Causal Forest with Instrumental Variable (BCF-IV) – to interpretably discover the subgroups with the largest or smallest causal effects in an instrumental variable setting.
These are many situations, ranging in complexity and importance, where one would like to estimate the causal effect of a defined intervention on a specific outcome.</description>
    </item>
    
    <item>
      <title>Frozen percolation on the binary tree is nonendogenous</title>
      <link>https://youngstats.github.io/post/2021/11/25/frozen-percolation-on-the-binary-tree-is-nonendogenous/</link>
      <pubDate>Thu, 25 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://youngstats.github.io/post/2021/11/25/frozen-percolation-on-the-binary-tree-is-nonendogenous/</guid>
      <description>In frozen percolation on a graph, there is a barrier located on eachedge. Initially, the barriers are closed and they are assignedi.i.d. uniformly distributed activation times. At its activation time,a barrier opens, provided it is not frozen. At a fixed set \(\Xi\) offreezing times, all barriers that percolate are frozen. In particular,if \(\Xi\) is the whole unit interval, this means that clusters stopgrowing as soon as they reach infinite size.</description>
    </item>
    
    <item>
      <title>Novel Algebraic Approaches to Maximum Likelihood Estimation</title>
      <link>https://youngstats.github.io/post/2021/10/04/novel-algebraic-approaches-to-maximum-likelihood-estimation/</link>
      <pubDate>Mon, 04 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://youngstats.github.io/post/2021/10/04/novel-algebraic-approaches-to-maximum-likelihood-estimation/</guid>
      <description>Novel Algebraic Approaches to Maximum Likelihood Estimation
The seventh “One World webinar” organized by YoungStatS will take placeon November 17th, 2021. Maximum likelihood estimation (MLE) is a tool indata analysis to estimate a probability distribution or density in astatistical model for given data. In recent decades, algebraic andcombinatorial tools have proved useful for computing MLEs andunderstanding the geometry of the MLE problem which in recent years ledto new and interesting results in combinatorics and algebraic geometry.</description>
    </item>
    
    <item>
      <title>Advancements in Symbolic Data Analysis</title>
      <link>https://youngstats.github.io/post/2021/09/30/advancements-in-symbolic-data-analysis/</link>
      <pubDate>Thu, 30 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://youngstats.github.io/post/2021/09/30/advancements-in-symbolic-data-analysis/</guid>
      <description>Advancements in Symbolic Data Analysis
The sixth “One World webinar” organized by YoungStatS will take place onNovember 8th, 2021. With the development of digital systems, very largedatasets have become routine. However, standard statistical approachesdo not have the power or flexibility to analyse these efficiently, andextract the required knowledge. Symbolic Data Analysis provides aframework allowing for the representation of data with intrinsicvariability, where the observed “values” are not just single real valuesor categories, but finite sets, intervals or distributions over a givendomain.</description>
    </item>
    
    <item>
      <title>Advances in Difference-in-Differences in Econometrics</title>
      <link>https://youngstats.github.io/post/2021/09/30/advances-in-difference-in-differences-in-econometrics/</link>
      <pubDate>Thu, 30 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://youngstats.github.io/post/2021/09/30/advances-in-difference-in-differences-in-econometrics/</guid>
      <description>Advances in Difference-in-Differences in Econometrics
The eighth “One World webinar” organized by YoungStatS will take placeon December 15th, 2021. The difference-in-differences design is aquasi-experimental identification strategy for estimating causal effectswhich has become the single most popular research design in thequantitative social sciences, and as such, it merits careful study byresearchers everywhere. It is also a flourishing field of presentresearch in econometrics. Selected younger researchers active in thearea will present their recent contributions on this topic.</description>
    </item>
    
    <item>
      <title>Optimal disclosure risk assessment</title>
      <link>https://youngstats.github.io/post/2021/09/30/optimal-disclosure-risk-assessment/</link>
      <pubDate>Thu, 30 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://youngstats.github.io/post/2021/09/30/optimal-disclosure-risk-assessment/</guid>
      <description>Disclosure risk for microdataProtection against disclosure is a legal and ethical obligation foragencies releasing microdata files for public use. Consider a microdatasample \({X}_n=(X_{1},\ldots,X_{n})\) of size \(n\) from a finitepopulation of size \(\bar{n}=n+\lambda n\), with \(\lambda&amp;gt;0\), such thateach sample record \(X_i\) contains two disjoint types of information:identifying categorical information and sensitive information.Identifying information consists of a set of categorical variables whichmight be matchable to known units of the population.</description>
    </item>
    
    <item>
      <title>Depth Quantile Functions</title>
      <link>https://youngstats.github.io/post/2021/07/01/depth-quantile-functions/</link>
      <pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://youngstats.github.io/post/2021/07/01/depth-quantile-functions/</guid>
      <description>Figure 1: Depth quantile functions for the wine data (d=13), class 2 vs class 3. Blue curves correspond to between class comparisons, red/pink correspond to within class comparisons.
A common technique in modern statistics is the so-called kernel trick, where data is mapped into a (usually) infinite-dimensional feature space, where various statistical tasks can be carried out. Relatedly, we introduce the depth quantile function (DQF), \(q_{ij}(\alpha)\) which similarly maps observations into an infinite dimensional space (the double index will become clear below), though in this case, these new representations of the data are functions of a one-dimensional variable \(\alpha\) which allows plotting.</description>
    </item>
    
    <item>
      <title>Concentration Inequalities in Machine Learning</title>
      <link>https://youngstats.github.io/post/2021/06/30/concentration-inequalities-in-machine-learning/</link>
      <pubDate>Wed, 30 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://youngstats.github.io/post/2021/06/30/concentration-inequalities-in-machine-learning/</guid>
      <description>The fifth “One World webinar” organized by YoungStatS will take place on September 15th, 2021. Selected young European researchers active in the areas of probability and machine learning will present their recent contributions. The webinar is joint cooperation between the Young Researchers Committee of the Bernoulli Society and the YoungStatS project.
When &amp;amp; Where:
Wednesday, September 15th, 17:00 CESTOnline, via Zoom. The registration form is available here.</description>
    </item>
    
  </channel>
</rss>
